{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from datetime import date, time, timedelta, datetime\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from torch.utils.data import Dataset\n",
        "from scipy import stats\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "import gc \n",
        "from statistics import mean, median, stdev\n",
        "import pickle\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "metadata": {
        "id": "lJUJo3aKYd6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b0ae3a-d0cc-49f7-a578-7fa09d6713ef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "new_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/final.zip\", index_col=0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mNjKn5K5dFX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "new_df.drop(['public_date', 'start_price', 'end_price', 'TICKER', 'price_year_before', 'date_before_year', 'adate', 'qdate', 'permno', 'CUSIP'], axis=1).columns"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CAPEI', 'bm', 'evm', 'pe_op_basic', 'pe_op_dil', 'pe_exi', 'pe_inc',\n",
              "       'ps', 'pcf', 'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm',\n",
              "       'roa', 'roe', 'roce', 'efftax', 'aftret_eq', 'aftret_invcapx',\n",
              "       'aftret_equity', 'pretret_noa', 'pretret_earnat', 'GProf',\n",
              "       'equity_invcap', 'debt_invcap', 'totdebt_invcap', 'capital_ratio',\n",
              "       'int_debt', 'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at',\n",
              "       'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct',\n",
              "       'ocf_lct', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets',\n",
              "       'debt_capital', 'de_ratio', 'intcov', 'intcov_ratio', 'cash_ratio',\n",
              "       'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn',\n",
              "       'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc',\n",
              "       'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing',\n",
              "       'divyield', 'PEG_1yrforward', 'PEG_ltgforward', 'cusip', 'growth',\n",
              "       'momentum'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4wQt7MK72E0",
        "outputId": "f6f2ccc2-04cb-4589-e8a6-bf904707dd40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "    \n",
        "# For rnn\n",
        "class CompanyDatasetRNN(Dataset):\n",
        "    \"\"\"\n",
        "    Custom torch dataset class for the annotated images\n",
        "\n",
        "    \"\"\"\n",
        "    SIZE_OF_SEQ = 9\n",
        "    def __init__(self, df):\n",
        "        self.standardize(df)\n",
        "        \n",
        "    \n",
        "    def standardize(self, df):\n",
        "        df_tmp = df.drop(['TICKER', 'price_year_before', 'date_before_year', 'adate', 'qdate', 'CUSIP', 'cusip'], axis=1)\n",
        "        \n",
        "        cols = df_tmp.columns\n",
        "        no_scaling = ['permno', 'public_date', 'growth', 'start_price', 'end_price']\n",
        "        for col in cols:\n",
        "          if not col in no_scaling:\n",
        "            df_tmp[col] = StandardScaler().fit_transform(np.array(df_tmp[col]).reshape(-1,1))\n",
        "        df_tmp = df_tmp.groupby('permno')\n",
        "        self.collate(df_tmp)\n",
        "    \n",
        "    def collate(self, data):\n",
        "        # Here dataset is chunked so it can be used in rnn\n",
        "        new_features = []\n",
        "        labels = []\n",
        "        prices = []\n",
        "        for company in data:\n",
        "            company = company[1]\n",
        "            for i in range(len(company)-(self.SIZE_OF_SEQ-1)):\n",
        "                batch = company.head(self.SIZE_OF_SEQ)\n",
        "                feature = batch.drop(['growth', 'public_date', 'permno', 'start_price', 'end_price'], axis=1)\n",
        "                feature = torch.tensor(feature.values)\n",
        "                label = 1+(batch.iloc[0]['growth'])\n",
        "                price = batch.iloc[0][['start_price', 'end_price']]\n",
        "                new_features.append(feature)\n",
        "                labels.append(label)\n",
        "                prices.append(price)\n",
        "                company = company.tail(len(company)-1)\n",
        "\n",
        "        self.features, self.growth, self.prices = new_features, labels, prices\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = self.features[idx]\n",
        "        growth = self.growth[idx]\n",
        "        prices = self.prices[idx].tolist()\n",
        "        return features, growth, prices\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "RSxx0WeqYzBn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          src_dictionary_size: The number of words in the source dictionary.\n",
        "          embed_size: The number of dimensions in the word embeddings.\n",
        "          hidden_size: The number of features in the hidden state of GRU.\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, num_layers=2, batch_first=True, dropout=0.2)\n",
        "        self.lstm = nn.LSTM(input_size=72, hidden_size=hidden_size, num_layers=2, batch_first=True, dropout=0.3)\n",
        "        self.fc1 = nn.Linear(72, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          pad_seqs of shape (max_seq_length, batch_size): Padded source sequences.\n",
        "          seq_lengths: List of sequence lengths.\n",
        "          hidden of shape (1, batch_size, hidden_size): Initial states of the GRU.\n",
        "\n",
        "        Returns:\n",
        "          outputs of shape (max_seq_length, batch_size, hidden_size): Padded outputs of GRU at every step.\n",
        "          hidden of shape (1, batch_size, hidden_size): Updated states of the GRU.\n",
        "        \"\"\"\n",
        "        #x = self.relu(self.fc1(x))\n",
        "        out, hidden = self.lstm(x)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc2(self.relu(out))\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size=1):\n",
        "        return torch.zeros(2, batch_size, self.hidden_size)\n",
        "    "
      ],
      "outputs": [],
      "metadata": {
        "id": "9B3f4wAWCH8G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "df = new_df.head(int(len(new_df))).sort_values('public_date', ascending=False).fillna(0)\n",
        "\n",
        "n_test = int(0.135 * len(df))\n",
        "n_val = n_test\n",
        "n_train = len(df) - (n_test+n_val)\n",
        "\n",
        "print(f\"Train size: {n_train}, test size: {n_test}, val size: {n_val}\")\n",
        "assert len(df) == (n_test + n_val + n_train)\n",
        "assert df.iloc[0]['public_date'] >= df.iloc[1]['public_date']\n",
        "assert df.iloc[0]['public_date'] > df.iloc[-1]['public_date']\n",
        "\n",
        "train_df = df.tail(n_train)\n",
        "test_val_df = df.head(n_test+n_val)\n",
        "val_df = test_val_df.tail(n_val)\n",
        "test_df = test_val_df.head(n_test)\n",
        "assert train_df.iloc[0]['public_date'] <= val_df.iloc[-1]['public_date']\n",
        "assert len(train_df) > 17000 and len(val_df) > 17000 and len(test_df) > 17000\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/permnos\", \"rb\") as fp:   # Unpickling\n",
        "    permnos = pickle.load(fp)\n",
        "test_df = test_df[test_df['permno'].isin(permnos)]\n",
        "print(len(test_df))\n",
        "\n",
        "\n",
        "\n",
        "ds_train = CompanyDatasetRNN(train_df)\n",
        "print(\"Trainset done\")\n",
        "ds_val = CompanyDatasetRNN(val_df)\n",
        "print(\"Valset done\")\n",
        "ds_test = CompanyDatasetRNN(test_df)\n",
        "print(\"Testset done\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 594761, test size: 109989, val size: 109989\n",
            "92204\n",
            "Trainset done\n",
            "Valset done\n",
            "Testset done\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHyLgeo8CIfB",
        "outputId": "3a61af48-e5b8-4b3c-9801-7df1ed50a09a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dl_train = DataLoader(ds_train, batch_size=batch_size, drop_last=True, shuffle=True)\n",
        "dl_val = DataLoader(ds_val, batch_size=batch_size, drop_last=True, shuffle=True)\n",
        "dl_test = DataLoader(ds_test, batch_size=64, drop_last=True, shuffle=True)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "KESiv4dPIER7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0kMUrMrvIUKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def print_progress(epoch, train_error, val_error, lr):\n",
        "    print('Epoch {}: Train error: {:.4f}, Test error: {:.4f}, lr: {}'.format(\n",
        "        epoch, train_error, val_error, lr))\n",
        "def compute_loss(mlp, dl):\n",
        "    mlp.eval()\n",
        "    tot_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dl:\n",
        "            hidden = mlp.init_hidden(batch_size).to(device)\n",
        "            x, y, _ = batch\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            outputs, hidden = mlp.forward(x.float(), hidden)\n",
        "            tot_loss += F.mse_loss(outputs, y.reshape(-1,1))\n",
        "            #tot_loss += F.l1_loss(outputs, y)\n",
        "        return (tot_loss)/len(dl)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q0fL3jY3C3ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YertLENowSWl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hidden_size = embed_size = 16\n",
        "model = RNN(embed_size, hidden_size)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "# Implement the training loop in this cell\n",
        "if True:\n",
        "    n_epochs = 6\n",
        "    train_errors = []  # Keep track of the training data\n",
        "    val_errors = []  # Keep track of the validation data\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, eps=1e-9, weight_decay=0.0001)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for idx, batch in enumerate(dl_train):\n",
        "            hidden = model.init_hidden(batch_size=batch_size).to(device)\n",
        "            features, growths, _ = batch\n",
        "            features, growths = features.to(device), growths.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs, hidden = model.forward(features.float(), hidden)\n",
        "            #loss = F.l1_loss(outputs, growths.float())\n",
        "            loss = F.mse_loss(outputs, growths.float().reshape(-1,1))\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            running_loss += loss\n",
        "            if idx % 1000 == 0:\n",
        "                print(f\"Epoch {epoch}, {int(idx/len(dl_train)*100)}%\")\n",
        "\n",
        "        lr = scheduler.get_last_lr()[0]\n",
        "        train_errors.append(running_loss/len(dl_train))\n",
        "        val_errors.append(compute_loss(model, dl_val))\n",
        "        print_progress(epoch, train_errors[-1], val_errors[-1], lr)\n",
        "        running_loss = 0\n",
        "        gc.collect()\n",
        "        scheduler.step()\n",
        "            \n",
        "    plt.plot(torch.stack(train_errors).cpu().detach())\n",
        "    plt.plot(torch.stack(val_errors).cpu().detach())\n",
        "    plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, 0%\n",
            "Epoch 0, 12%\n",
            "Epoch 0, 24%\n",
            "Epoch 0, 36%\n",
            "Epoch 0, 48%\n",
            "Epoch 0, 60%\n",
            "Epoch 0, 72%\n",
            "Epoch 0, 84%\n",
            "Epoch 0, 96%\n",
            "Epoch 0: Train error: 2.0309, Test error: 5.4773, lr: 0.001\n",
            "Epoch 1, 0%\n",
            "Epoch 1, 12%\n",
            "Epoch 1, 24%\n",
            "Epoch 1, 36%\n",
            "Epoch 1, 48%\n",
            "Epoch 1, 60%\n",
            "Epoch 1, 72%\n",
            "Epoch 1, 84%\n",
            "Epoch 1, 96%\n",
            "Epoch 1: Train error: 1.9553, Test error: 5.4230, lr: 0.001\n",
            "Epoch 2, 0%\n",
            "Epoch 2, 12%\n",
            "Epoch 2, 24%\n",
            "Epoch 2, 36%\n",
            "Epoch 2, 48%\n",
            "Epoch 2, 60%\n",
            "Epoch 2, 72%\n",
            "Epoch 2, 84%\n",
            "Epoch 2, 96%\n",
            "Epoch 2: Train error: 1.9064, Test error: 5.3759, lr: 0.001\n",
            "Epoch 3, 0%\n",
            "Epoch 3, 12%\n",
            "Epoch 3, 24%\n",
            "Epoch 3, 36%\n",
            "Epoch 3, 48%\n",
            "Epoch 3, 60%\n",
            "Epoch 3, 72%\n",
            "Epoch 3, 84%\n",
            "Epoch 3, 96%\n",
            "Epoch 3: Train error: 1.8375, Test error: 5.3496, lr: 0.0001\n",
            "Epoch 4, 0%\n",
            "Epoch 4, 12%\n",
            "Epoch 4, 24%\n",
            "Epoch 4, 36%\n",
            "Epoch 4, 48%\n",
            "Epoch 4, 60%\n",
            "Epoch 4, 72%\n",
            "Epoch 4, 84%\n",
            "Epoch 4, 96%\n",
            "Epoch 4: Train error: 1.8155, Test error: 5.3580, lr: 0.0001\n",
            "Epoch 5, 0%\n",
            "Epoch 5, 12%\n",
            "Epoch 5, 24%\n",
            "Epoch 5, 36%\n",
            "Epoch 5, 48%\n",
            "Epoch 5, 60%\n",
            "Epoch 5, 72%\n",
            "Epoch 5, 84%\n",
            "Epoch 5, 96%\n",
            "Epoch 5: Train error: 1.7997, Test error: 5.3461, lr: 0.0001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "CajecOmICLIq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1681a7e-d322-4c11-feb2-0c7e7838ed03"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.plot(torch.stack(train_errors).cpu().detach())\n",
        "plt.plot(torch.stack(val_errors).cpu().detach())\n",
        "plt.show()\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/rnngoodmabye.pth\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVwUlEQVR4nO3dbYxcV33H8d9vHnZtr23Sxltw/cCWgiq1iMepC02K2iBQgChBBaQgQQsCWSAiQkuFSl8gkXf0BUVtVVIrqRSemiBIqEmBYokgmqqEroMTSJy2FgQlJtSbhHjt7K53Hv59MXd3Z8YzO3d3Z3ayx9+PNLrn3nPunf8k8u/MvXNnxxEhAMDWVxh1AQCAwSDQASARBDoAJIJAB4BEEOgAkIjSqJ54z549MTU1NaqnB4At6fjx409GxGS3vpEF+tTUlKanp0f19ACwJdn+Wa8+LrkAQCIIdABIBIEOAIkg0AEgEbk+FLX9qKRzkuqSahFR6ej/Q0n/Iumn2aY7I+KmwZUJAOhnLXe5/FFEPLlK/79HxDUbLQgAsD5ccgGAROR9hx6Svm07JP1jRBzpMua1th+Q9HNJfxERD3UOsH1Y0mFJOnjw4PoqPnNS+vGd0tiENL5TGtvZbI+1tiek8V3NZXFMstf3XACwheQN9Csj4rTtX5N0zPYjEfG9lv77Jb0wIs7bfrOkr0l6SedBsongiCRVKpX1/SH2Myel7/11/vGFUpew75wIWparThLZerG8rtIBYJhyBXpEnM6WZ2zfJemQpO+19M+2tL9h+x9s7+lzzX19XvrH0m+/VarOSYvPSovnuy8vnF+9b+6x9u3Vufw1FMc2OEl09JUnpOLIvrQLIBF9U8T2hKRCRJzL2m+UdFPHmBdI+r+ICNuH1Lw2/9QwCpYkFQrNIBzfKen5gzlmo74ySVw0GSy1O/uelRbPrbSffVK60LJem8///KVtPSaClvXyjuZjbEeO9oRU3i6Vtjf/ewFIXp63hc+XdJeb16FLkr4UEd+y/QFJioibJb1d0gdt1yTNS7o+ttpv2xWKzevu47ukXQM6Zr0mVZ9tmQxawr5zolg8n00WLX0XzknnfrHSV51f2ySxpLyjGe7lLOTHdqzS7pgQ2tpd9invYMIAniM8qtytVCrBH+dah0ajGeqLc83JotrZzpZLZxvV+WxSmcvXXs+EUdqeBf3EyuTRdULoMzl07l/a1ry8VRxj0gAyto93fhdoCRdut5pCYeW6vbr+Bc2NWZowlieHuWxymFul3TqxtGyfe1qqPt6+fS2fVbRycSXci+WOZa92eQ1jc7QL5XzjL9XJJyJ7NNof6tzWsS5LLjTPkluXLra0C9ytlgOBjnatE8bEnsEfv9GQagsXn0H0OtNoVKV6VaovZsul9mKPdrW5b/2XvfsbWbtRG/zrk9Yw+XSZIFy8OBD7hmSX/ov2zzOmW/j2qqNHTcO0HOzFjtDPlsuTwVK7z/aLJg7n2N456XQeu8v2i2otSPt/V5q6cuD/iQh0bK5CoXmZZWzHcCaMtWg0VsK970TRrb2RfZcmnzmpcXZlW6O2Eg5tD/doFzoCpGObcuzX1t9vTHb20W/M8nFWO56b9UnNCaFRl6Lepd1YfXsjW19uR4/tjR7Pk22vd3n+RqPLMfpt71Jrpyv/jEAHBqpQkArjUml81JUgdZ1BXygO5WkIdAAYtkJBm/GXVi7RT28AID0EOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASkSvQbT9q+0e2T9i+6Hfj3PS3tk/ZftD2qwZfKgBgNWv587l/FBFP9uh7k6SXZI/fk/TZbAkA2CSDuuRynaTPRdP3JV1me++Ajg0AyCFvoIekb9s+bvtwl/59kh5rWX8829bG9mHb07anZ2Zm1l4tAKCnvIF+ZUS8Ss1LKx+y/br1PFlEHImISkRUJieH8Iv1AHAJyxXoEXE6W56RdJekQx1DTks60LK+P9sGANgkfQPd9oTtXUttSW+U9OOOYUcl/Ul2t8trJJ2NiCcGXi0AoKc8d7k8X9JdtpfGfykivmX7A5IUETdL+oakN0s6JWlO0nuHUy4AoJe+gR4RP5H08i7bb25ph6QPDbY0AMBa8E1RAEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJyB3otou2f2j77i5977E9Y/tE9nj/YMsEAPST50eil9wo6aSk3T3674iIGzZeEgBgPXK9Q7e9X9JbJN0y3HIAAOuV95LLZyR9TFJjlTFvs/2g7a/YPtBtgO3DtqdtT8/MzKy1VgDAKvoGuu1rJJ2JiOOrDPu6pKmIeJmkY5Ju6zYoIo5ERCUiKpOTk+sqGADQXZ536FdIutb2o5Jul3SV7S+0DoiIpyLiQrZ6i6RXD7RKAEBffQM9Ij4eEfsjYkrS9ZK+ExHvah1je2/L6rVqfngKANhEa7nLpY3tmyRNR8RRSR+2fa2kmqSnJb1nMOUBAPJyRIzkiSuVSkxPT4/kuQFgq7J9PCIq3fr4pigAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkIneg2y7a/qHtu7v0jdu+w/Yp2/fZnhpkkQCA/tbyDv1G9f7x5/dJ+mVEvFjS30j61EYLAwCsTa5At71f0lsk3dJjyHWSbsvaX5H0etveeHkAgLzyvkP/jKSPSWr06N8n6TFJioiapLOSLt9wdQCA3PoGuu1rJJ2JiOMbfTLbh21P256emZnZ6OEAAC3yvEO/QtK1th+VdLukq2x/oWPMaUkHJMl2SdLzJD3VeaCIOBIRlYioTE5ObqhwAEC7voEeER+PiP0RMSXpeknfiYh3dQw7KulPs/bbszEx0EoBAKsqrXdH2zdJmo6Io5JulfR526ckPa1m8AMANtGaAj0ivivpu1n7Ey3bFyS9Y5CFAQDWhm+KAkAiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIRN9At73N9g9sP2D7Iduf7DLmPbZnbJ/IHu8fTrkAgF7y/KboBUlXRcR522VJ99r+ZkR8v2PcHRFxw+BLBADk0TfQIyIknc9Wy9kjhlkUAGDtcl1Dt120fULSGUnHIuK+LsPeZvtB21+xfWCgVQIA+soV6BFRj4hXSNov6ZDtl3YM+bqkqYh4maRjkm7rdhzbh21P256emZnZSN0AgA5russlIp6RdI+kqzu2PxURF7LVWyS9usf+RyKiEhGVycnJ9dQLAOghz10uk7Yvy9rbJb1B0iMdY/a2rF4r6eQgiwQA9JfnLpe9km6zXVRzAvhyRNxt+yZJ0xFxVNKHbV8rqSbpaUnvGVbBAIDu3LyJZfNVKpWYnp4eyXMDwFZl+3hEVLr18U1RAEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJyPMj0dts/8D2A7Yfsv3JLmPGbd9h+5Tt+2xPDaNYAEBved6hX5B0VUS8XNIrJF1t+zUdY94n6ZcR8WJJfyPpU4MtEwDQT99Aj6bz2Wo5e3T+svR1km7L2l+R9HrbHliVAIC+cl1Dt120fULSGUnHIuK+jiH7JD0mSRFRk3RW0uVdjnPY9rTt6ZmZmY1VDgBokyvQI6IeEa+QtF/SIdsvXc+TRcSRiKhERGVycnI9hwAA9LCmu1wi4hlJ90i6uqPrtKQDkmS7JOl5kp4aRIEAgHzy3OUyafuyrL1d0hskPdIx7KikP83ab5f0nYjovM4OABiiUo4xeyXdZruo5gTw5Yi42/ZNkqYj4qikWyV93vYpSU9Lun5oFQMAuuob6BHxoKRXdtn+iZb2gqR3DLY0AMBa8E1RAEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJyPMj0Qds32P7YdsP2b6xy5g/tH3W9ons8YluxwIADE+eH4muSfpoRNxve5ek47aPRcTDHeP+PSKuGXyJAIA8+r5Dj4gnIuL+rH1O0klJ+4ZdGABgbdZ0Dd32lKRXSrqvS/drbT9g+5u2f6fH/odtT9uenpmZWXOxAIDecge67Z2SvirpIxEx29F9v6QXRsTLJf2dpK91O0ZEHImISkRUJicn11szAKCLXIFuu6xmmH8xIu7s7I+I2Yg4n7W/Ialse89AKwUArCrPXS6WdKukkxHx6R5jXpCNk+1D2XGfGmShAIDV5bnL5QpJ75b0I9snsm1/JemgJEXEzZLeLumDtmuS5iVdHxExhHoBAD30DfSIuFeS+4z5e0l/P6iiAABrxzdFASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkIs+PRB+wfY/th20/ZPvGLmNs+29tn7L9oO1XDadcaebcBf3HqSf149Nn9djTc5pdqKrR4OdLASDPj0TXJH00Iu63vUvScdvHIuLhljFvkvSS7PF7kj6bLQfuvp8+pRu+9MO2bQVLu7eX9byWR+f6Zd36dpS1a7wke9WfTAWALSHPj0Q/IemJrH3O9klJ+yS1Bvp1kj4XESHp+7Yvs70323egfv839+j2w6/R2fmqzs5XNZstz85X9czcSvv0L+eX27VV3sF3mwxWezAZAHiuyvMOfZntKUmvlHRfR9c+SY+1rD+ebWsLdNuHJR2WpIMHD66t0syvTozpNS+6PPf4iNDcYn053Nsec122rWEyKBas3dtKPc8KLnrsWGnvZDIAMGC5A932TklflfSRiJhdz5NFxBFJRySpUqlsyoVv25oYL2livKRfv2z7mvbtnAyWzgBmu00OHZPBM/NV1TcwGVy2o/2sYPe2snaMFbVjrKTtY0XtGCuqXOQzbQArcgW67bKaYf7FiLizy5DTkg60rO/Ptm1pG50Mnl2aDFrOBHpNBs/MV/V4y5nBapPBknLR2l5uhvyOseJy0Hdbb44rZttb+svtk8TS9rFigTMIYIvpG+hu/qu+VdLJiPh0j2FHJd1g+3Y1Pww9O4zr51uJbe0cL2nneEn7BjAZzC5UNb9Y19xiXXOLtWa7Ws+21TS3WF/uf2a+qifOzmdjm/0L1caaaigWvBzwrRNC2ySxPCF0TBJLE0O5pInxlv5ys3+8xGQBDEOed+hXSHq3pB/ZPpFt+ytJByUpIm6W9A1Jb5Z0StKcpPcOvtRLx0Ymg14ajdB8tb4S/NX2SWB5klisZ+Mu7p9brOvcQk1nZi9orto+PtZwAa1gtZ0VrJw9tJ8pTIyVtGtbWbu3l7R7W1m7tpW0e3u23Na8DLVzW0nFApMDIOW7y+VeSav+i8nubvnQoIrC4BUKK5ePBi0itFBtrEwC1S6TRLb+bMskMZ9NKq39T56/sLz/sxea/f3sGi9dFPYXhf8qfdvKxYH/NwFGYfD/unHJsa3t2eWW/Pcf5VOrN3RuoaZzCzXNLjQvPc3ON9vnFmqana8u953L+n4xu6D/PbMypt/nEWPFQs+zgL4Twvaydo6VVOAsAc8BBDqe00rFgn5lYky/MjG2rv2X7lRanhBaJoDZjgmhtf3E2YXl9fnq6mcJtrRzvD3sd6/xTGG8xFkCNo5AR9Ja71R6wfO2resYi7WGzi20nglcPBHMdvT9/JkFPbJwTrPzVZ2/UFO/m5bGSwXtym5NLRWtcqGgUtEqFQsqF9zcViyoVMi2Fa1SNmZpbM/+rF3OjlcqZGM7tpezfYuF1fdZqa3Z5uzkuYNAB/oYKxV0+c5xXb5zfF37NxqhZxdrF00I3SaH+cW6qo1Qrd5QrR5t7fO1WnNbvaFatr1aD9UajY7toWqjsaYPqjeiYLVNCO2TSeck0z6mXLSKhWa7UGj2FwtW0VaxmC0LS2NW2t3GrPQXVCyobVkqWAV3OUa239JzF9ycqFaOWVChoLbl0vO2HvO5MqkR6MCQFQrWrm1l7dpW1q9rMHct5VFv9A//ajZZ1BpZfzYZ1OrZPm2TSyM7ZratZf/e+3R/7oVqQ7V6TdV6qN4I1aO5rDUaajSkWqOhekOqZ8/Z7As1orncrMlqLVonhrbJwr6o752HDur9f/Ciwdcw8CMCeE5ohkqa1+YbLZPActh3hP7Sej2bHFoni0Y0J6+lyaRt/+X9Wh49jtm2zMbU6+21tT5q2bH2rPNsrx8CHcCWUyhYBVnccdqOPwYCAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASIRjRN+htT0j6Wfr3H2PpCcHWM5WwGu+NPCaLw0bec0vjIjJbh0jC/SNsD0dEZVR17GZeM2XBl7zpWFYr5lLLgCQCAIdABKxVQP9yKgLGAFe86WB13xpGMpr3pLX0AEAF9uq79ABAB0IdABIxJYLdNtX2/5v26ds/+Wo6xk22/9k+4ztH4+6ls1i+4Dte2w/bPsh2zeOuqZhs73N9g9sP5C95k+OuqbNYLto+4e27x51LZvB9qO2f2T7hO3pgR9/K11Dt12U9D+S3iDpcUn/JemdEfHwSAsbItuvk3Re0uci4qWjrmcz2N4raW9E3G97l6Tjkt6a+P9nS5qIiPO2y5LulXRjRHx/xKUNle0/l1SRtDsirhl1PcNm+1FJlYgYyheptto79EOSTkXETyJiUdLtkq4bcU1DFRHfk/T0qOvYTBHxRETcn7XPSTopad9oqxquaDqfrZazx9Z5t7UOtvdLeoukW0ZdSyq2WqDvk/RYy/rjSvwf+qXO9pSkV0q6b7SVDF92+eGEpDOSjkVE6q/5M5I+Jqkx6kI2UUj6tu3jtg8P+uBbLdBxCbG9U9JXJX0kImZHXc+wRUQ9Il4hab+kQ7aTvcRm+xpJZyLi+Khr2WRXRsSrJL1J0oeyS6oDs9UC/bSkAy3r+7NtSEx2Hfmrkr4YEXeOup7NFBHPSLpH0tWjrmWIrpB0bXZN+XZJV9n+wmhLGr6IOJ0tz0i6S83LyAOz1QL9vyS9xPZv2B6TdL2koyOuCQOWfUB4q6STEfHpUdezGWxP2r4sa29X84P/R0Zb1fBExMcjYn9ETKn57/g7EfGuEZc1VLYnsg/5ZXtC0hslDfTutS0V6BFRk3SDpH9T84OyL0fEQ6Otarhs/7Ok/5T0W7Yft/2+Ude0Ca6Q9G4137WdyB5vHnVRQ7ZX0j22H1TzjcuxiLgkbuW7hDxf0r22H5D0A0n/GhHfGuQTbKnbFgEAvW2pd+gAgN4IdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJCI/wfhv21coJiDfQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "INKGa6BVn4CN",
        "outputId": "7f04a8f6-8813-4097-a6d4-4876cdbf4be0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def r_squared(preds, targets, y_bar):\n",
        "    ss_tot = ((targets - preds)**2).sum()\n",
        "    ss_res = ((targets - y_bar)**2).sum()\n",
        "    return 1 - (ss_tot/ss_res)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "ECK2izJ4qQSM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "'''\n",
        "ds_test = CompanyDatasetRNN(test_df)\n",
        "'''\n",
        "hidden_size = embed_size = 16\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = RNN(embed_size, hidden_size)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/rnngoodmabye.pth\", map_location=torch.device(device)))\n",
        "model.to(device)\n",
        "preds_list = []\n",
        "growths_list = []\n",
        "prices_list = []\n",
        "accuracy_levels = []\n",
        "with torch.no_grad():\n",
        "    for batch in dl_test:\n",
        "        features, growths, prices = batch\n",
        "        features, growths = features.to(device), growths.to(device)\n",
        "        hidden = model.init_hidden(batch_size=batch_size).to(device)\n",
        "        preds, hidden = model.forward(features.float(), hidden)\n",
        "        preds_list += preds[:, 0].tolist()\n",
        "        growths_list += growths.tolist()\n",
        "        prices_list += prices\n",
        "        accuracy_level = 1 - abs(((1+growths)/(1+preds)[:, 0])-1)\n",
        "        accuracy_levels += accuracy_level.tolist()\n",
        "    r2 = r_squared(pd.Series(preds_list), pd.Series(growths_list), 1.09783173099033)\n",
        "print(f\"Test R2: {r2}\")\n",
        "print(f\"Accuracy level median: {median(accuracy_levels)}, Mean: {mean(accuracy_levels)}, Std; {stdev(accuracy_levels)}\")\n",
        "print(pd.Series(growths_list).describe())\n",
        "print(pd.Series(preds_list).describe())\n",
        "print(test_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R2: 0.04768943137363324\n",
            "Accuracy level median: 0.8316985331298603, Mean: 0.7054881609991223, Std; 0.8823276593075866\n",
            "count    68480.000000\n",
            "mean         1.439412\n",
            "std          2.693380\n",
            "min          0.021845\n",
            "25%          0.794273\n",
            "50%          1.070295\n",
            "75%          1.457672\n",
            "max        209.708274\n",
            "dtype: float64\n",
            "count    68480.000000\n",
            "mean         1.316929\n",
            "std          0.762830\n",
            "min          0.817474\n",
            "25%          1.022351\n",
            "50%          1.084986\n",
            "75%          1.233372\n",
            "max          8.562413\n",
            "dtype: float64\n",
            "         permno       adate     qdate public_date   CAPEI     bm     evm  \\\n",
            "1128026   80577  20191231.0  20200930  2020-11-30   0.000  0.465  -3.584   \n",
            "1102989   15914  20191231.0  20200930  2020-11-30 -68.075  0.000 -36.790   \n",
            "1061460   91968  20200930.0  20200930  2020-11-30  57.604  0.406  46.892   \n",
            "94825     77462  20200131.0  20200731  2020-11-30   5.292  1.726  58.689   \n",
            "1104015   93426  20191231.0  20200930  2020-11-30  31.959  0.744  11.434   \n",
            "...         ...         ...       ...         ...     ...    ...     ...   \n",
            "507429    77785  20161231.0  20170331  2017-07-31  24.184  0.650  11.205   \n",
            "298024    27167  20161031.0  20170430  2017-07-31  -1.935  0.157  -9.391   \n",
            "1076154   92400  20161231.0  20170331  2017-06-30  52.720  0.353 -12.891   \n",
            "859131    92318  20161231.0  20170331  2017-06-30  39.247  0.538  11.687   \n",
            "825999    14778  20161231.0  20170331  2017-06-30  25.040  1.939   7.160   \n",
            "\n",
            "         pe_op_basic  pe_op_dil  pe_exi  ...  PEG_ltgforward  TICKER  \\\n",
            "1128026       -2.264     -2.264  -2.156  ...           0.000    ARMP   \n",
            "1102989      -12.081    -12.081 -10.108  ...           0.000    WKHS   \n",
            "1061460       55.484     57.333  59.310  ...           0.000    TFSL   \n",
            "94825         -3.557     -3.545  -0.865  ...          -0.063       M   \n",
            "1104015       25.216     25.435  27.594  ...           0.000     VPG   \n",
            "...              ...        ...     ...  ...             ...     ...   \n",
            "507429        23.229     23.351  23.850  ...           2.385    WIRE   \n",
            "298024        -1.000     -1.000  -1.274  ...           0.000    ITUS   \n",
            "1076154      -15.469    -15.469 -11.088  ...           0.000      LL   \n",
            "859131        21.844     21.844  26.325  ...           0.000    TOWN   \n",
            "825999         6.693      9.942  11.130  ...           0.000     TSQ   \n",
            "\n",
            "            cusip  date_before_year  start_price  end_price     CUSIP  \\\n",
            "1128026  04216R10        2019-12-02         3.17       4.96  04216R10   \n",
            "1102989  98138J20        2019-12-02        25.37       5.84  98138J20   \n",
            "1061460  87240R10        2019-12-02        17.20      18.00  87240R10   \n",
            "94825    55616P10        2019-12-02        10.21      28.50  55616P10   \n",
            "1104015  92835K10        2019-12-02        29.25      34.33  92835K10   \n",
            "...           ...               ...          ...        ...       ...   \n",
            "507429   29256210        2016-08-01        44.60      48.75  29256210   \n",
            "298024   45069V20        2016-08-01         0.79       3.29  03528H10   \n",
            "1076154  55003T10        2016-06-30        25.06      24.35  55003T10   \n",
            "859131   89214P10        2016-06-30        30.80      32.10  89214P10   \n",
            "825999   89223110        2016-06-30        10.24       6.47  89223110   \n",
            "\n",
            "         price_year_before    growth  momentum  \n",
            "1128026               4.23  0.564669 -0.250591  \n",
            "1102989               2.86 -0.769807  7.870629  \n",
            "1061460              19.78  0.046512 -0.130435  \n",
            "94825                15.40  1.791381 -0.337013  \n",
            "1104015              33.72  0.173675 -0.132562  \n",
            "...                    ...       ...       ...  \n",
            "507429               36.99  0.093049  0.205731  \n",
            "298024                3.18  3.164557 -0.751572  \n",
            "1076154              15.42 -0.028332  0.625162  \n",
            "859131               21.65  0.042208  0.422633  \n",
            "825999                7.89 -0.368164  0.297845  \n",
            "\n",
            "[92204 rows x 84 columns]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANIgni1xF4Po",
        "outputId": "fe4e216f-9145-410b-f8fb-c5b1449289b5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "gc.collect()\n",
        "growths, preds = growths, preds\n",
        "#tgt_prices = prices[1]\n",
        "#tgt_ish = prices[0] * (growths)\n",
        "\n",
        "#pred_prices = prices[0] * (preds)\n",
        "\n",
        "accuracy_level = 1 - abs((prices[1].to(device)/(prices[0].to(device) * (preds))-1))\n",
        "#test = accuracy_level.sort_values()\n",
        "print(accuracy_level.describe())\n",
        "\n",
        "\n",
        "print(accuracy_level)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e53adb2ccb4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#pred_prices = prices[0] * (preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0maccuracy_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#test = accuracy_level.sort_values()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 21.41 GiB (GPU 0; 11.17 GiB total capacity; 280.16 MiB already allocated; 10.20 GiB free; 458.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "metadata": {
        "id": "jzsQYL7FaGi3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "afeb28d5-cb30-40e3-daec-57c779a64975"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}